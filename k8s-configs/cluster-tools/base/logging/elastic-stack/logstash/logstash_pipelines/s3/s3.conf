#input {
#  http {
#    port => 8081
#    id => "s3_in"
#    max_pending_requests => 1000
#    threads => 2
#  }
#}

input {
  kafka {
    bootstrap_servers => "logging-kafka-bootstrap.kafka.svc:9092"
    topics => ["s3"]
    codec => "json"
    consumer_threads => 2
    group_id => "logstash"
    id => 'main_in'
    enable_auto_commit => true
    auto_offset_reset => "earliest"
  }
}

filter {
      ### Remove unneeded fields came from fluent-bit and set appropriate directory for s3
      mutate {
        add_field => { "[@metadata][s3_key]" => "%{[kubernetes][pod_name]}_%{[kubernetes][namespace_name]}_%{[kubernetes][container_name]}" }
        remove_field => [ "headers", "host","date"]
      }
}
output {
      s3 {
        region => "${AWS_REGION}"
        bucket => "${S3_BUCKET_NAME}"
        prefix => "/application/%{[@metadata][s3_key]}/%{+YYYY}/%{+MM}/%{+dd}/%{+HH}/%{+mm}/%{+ss}"
        time_file => "1"
        codec => "json"
        id => "s3_out"
      }
}